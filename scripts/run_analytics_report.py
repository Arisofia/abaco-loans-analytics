"""
Abaco Loans Analytics - Executive Report Runner
Standard: Excellence & Vibe Solutioning
"""

import argparse
import logging
import sys
from pathlib import Path
from typing import Any, Dict, Optional

# Standard MIT-caliber engineering imports
from src.pipeline.orchestrator import UnifiedPipeline
from src.pipeline.utils import utc_now

# Configure logging with structured clarity
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s",
    handlers=[logging.StreamHandler(sys.stdout)],
)
logger = logging.getLogger("abaco.analytics.report")


class AnalyticsReportRunner:
    """
    Enterprise-grade report runner for Abaco Loans Analytics.
    Orchestrates ingestion, transformation, and KPI calculation.
    """

    def __init__(self, data_path: Path, output_path: Path, config_path: Optional[Path] = None):
        """
        Initialize the report runner.

        Args:
            data_path: Path to input data file
            output_path: Path to save the final markdown report
            config_path: Optional custom pipeline config path
        """
        self.data_path = data_path
        self.output_path = output_path
        self.pipeline = UnifiedPipeline(config_path=config_path)
        logger.info("AnalyticsReportRunner initialized for data: %s", data_path)

    def run(self) -> None:
        """
        Execute the full pipeline and generate the professional report.
        """
        try:
            logger.info("Starting Daily Intelligence Cycle via Unified Pipeline")

            # Execute full pipeline (Ingestion -> Transformation -> Calculation -> Output)
            summary = self.pipeline.run(str(self.data_path))

            if summary.get("status") == "failed":
                logger.error("Pipeline execution failed: %s", summary.get("error"))
                sys.exit(1)

            # Generate the executive report artifact
            self._generate_report(summary)
            logger.info("Market-leading report generated at %s", self.output_path)

        except Exception as exc:
            logger.critical("Fatal system error during report execution: %s", exc, exc_info=True)
            sys.exit(1)

    def _generate_report(self, summary: Dict[str, Any]) -> None:
        """
        Synthesize pipeline outputs into a professional Markdown report.

        Args:
            summary: Result summary from the UnifiedPipeline
        """
        run_id = summary.get("run_id", "unknown")
        phases = summary.get("phases", {})

        report_lines = [
            "# ABACO LOANS ANALYTICS - FINANCIAL INTELLIGENCE",
            f"**Run ID**: `{run_id}`",
            f"**Execution Date**: {utc_now()}",
            f"**Environment**: {self.pipeline.config.environment.upper()}",
            "",
            "## 1. DATA OPERATIONS SUMMARY",
            "- **Ingestion Status**: âœ… SUCCESS",
            f"- **Input Source**: `{self.data_path.name}`",
            f"- **Records Ingested**: {phases.get('ingestion', {}).get('rows', 0)}",
            f"- **Transformation Masking**: {', '.join(phases.get('transformation', {}).get('masked_columns', [])) or 'None'}",
            "",
            "## 2. KPI PERFORMANCE INDICATORS",
        ]

        # List calculated metrics
        metrics = phases.get("calculation", {}).get("metrics", [])
        if metrics:
            for metric in metrics:
                report_lines.append(f"- **{metric}**: Successfully Calculated")
        else:
            report_lines.append("- *No metrics calculated in this run.*")

        report_lines.extend(
            [
                "",
                "## 3. AUDIT & TRACEABILITY",
                f"- **Manifest Path**: `{phases.get('output', {}).get('manifest', 'N/A')}`",
                f"- **Audit Trail**: Immutable logs recorded in `logs/runs/{run_id}/`",
                "- **Compliance Level**: Enterprise Standard",
                "",
                "## 4. ANOMALY DETECTION",
            ]
        )

        anomalies = phases.get("calculation", {}).get("anomalies", [])
        if anomalies:
            report_lines.append(
                f"ðŸ”´ **{len(anomalies)} anomalies detected** requiring investigation."
            )
        else:
            report_lines.append("ðŸŸ¢ No statistical anomalies detected in this dataset.")

        report_lines.extend(
            [
                "",
                "---",
                "*This report was generated by the Abaco Multi-Agent Intelligence Ecosystem.*",
                "*Confidential - For Internal Use Only*",
            ]
        )

        # Ensure output directory exists
        self.output_path.parent.mkdir(parents=True, exist_ok=True)
        self.output_path.write_text("\n".join(report_lines), encoding="utf-8")


def main():
    """Main entry point for the report runner script."""
    parser = argparse.ArgumentParser(
        description="Abaco Financial Intelligence - Automated Report Runner"
    )
    parser.add_argument("--data", required=True, help="Input data file path (CSV/Parquet)")
    parser.add_argument("--output", required=True, help="Output report path (Markdown)")
    parser.add_argument("--config", help="Optional pipeline config override")

    args = parser.parse_args()

    data_path = Path(args.data)
    output_path = Path(args.output)
    config_path = Path(args.config) if args.config else None

    if not data_path.exists():
        logger.error("Input data file does not exist: %s", data_path)
        sys.exit(1)

    runner = AnalyticsReportRunner(data_path, output_path, config_path=config_path)
    runner.run()


if __name__ == "__main__":
    main()
