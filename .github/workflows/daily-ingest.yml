name: Daily Data Ingestion

on:
  schedule:
    - cron: '0 5 * * *'
  workflow_dispatch:

jobs:
  ingest-data:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          cache-dependency-path: |
            requirements.txt
            apps/analytics/requirements.txt
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          if [ -f apps/analytics/requirements.txt ]; then
            pip install -r apps/analytics/requirements.txt
          fi

                - name: Install Playwright
        run: |
          pip install playwright
          playwright install chromium
      
      - name: Run Cascade scraper
        run: python scripts/scrape_cascade.py --loan-tape
        env:
          CASCADE_USERNAME: ${{ secrets.CASCADE_USERNAME }}
          CASCADE_PASSWORD: ${{ secrets.CASCADE_PASSWORD }}
          CASCADE_PID: abaco
      - name: Run data ingestion pipeline
        run: |
          python scripts/run_data_pipeline.py
      - name: Notify Slack on Success
        if: success()
        uses: slackapi/slack-github-action@v2
        with:
          webhook-type: INCOMING_WEBHOOK
          payload: |
            {
              "text": ":tada: Daily data ingestion completed successfully!",
              "attachments": [
                {
                  "title": "Workflow Run",
                  "title_link": "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}",
                  "color": "#36a64f"
                }
              ]
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
