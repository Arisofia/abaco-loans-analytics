name: Unified Multi-Agent Data Pipeline

on:
  schedule:
    # Run daily at 4:00 AM CET (3:00 AM UTC) - before agent workflows
    - cron: "0 3 * * *"
  workflow_dispatch:

jobs:
  ingest-all-sources:
    runs-on: ubuntu-latest
    env:
      SUPABASESERVICEROLE: ${{ secrets.SUPABASE_SERVICE_ROLE }}
      CASCADEUSERNAME: ${{ secrets.CASCADEUSERNAME }}
      CASCADEPASSWORD: ${{ secrets.CASCADEPASSWORD }}
      HUBSPOTTOKEN: ${{ secrets.HUBSPOT_API_TOKEN }}
      OPIKTOKEN: ${{ secrets.OPIK_TOKEN }}
      SLACKBOTTOKEN: ${{ secrets.SLACK_BOT_TOKEN }}

    steps:
      - name: Check secrets availability
        id: check-secrets
        run: |
          if [ -n "${{ secrets.CASCADEUSERNAME }}" ] && [ -n "${{ secrets.CASCADEPASSWORD }}" ]; then
            echo "cascade_available=true" >> $GITHUB_OUTPUT
          else
            echo "cascade_available=false" >> $GITHUB_OUTPUT
          fi
          if [ -n "${{ secrets.HUBSPOT_API_TOKEN }}" ]; then
            echo "hubspot_available=true" >> $GITHUB_OUTPUT
          else
            echo "hubspot_available=false" >> $GITHUB_OUTPUT
          fi
          if [ -n "${{ secrets.SUPABASE_SERVICE_ROLE }}" ]; then
            echo "supabase_available=true" >> $GITHUB_OUTPUT
          else
            echo "supabase_available=false" >> $GITHUB_OUTPUT
          fi
          if [ -n "${{ secrets.SLACK_BOT_TOKEN }}" ]; then
            echo "slack_available=true" >> $GITHUB_OUTPUT
          else
            echo "slack_available=false" >> $GITHUB_OUTPUT
          fi
          if [ -n "${{ secrets.OPIK_TOKEN }}" ]; then
            echo "opik_available=true" >> $GITHUB_OUTPUT
          else
            echo "opik_available=false" >> $GITHUB_OUTPUT
          fi

      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Setup Python Environment
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Ingest Cascade Data
        id: cascade
        if: hashFiles('scripts/ingest_cascade.py') != '' && steps.check-secrets.outputs.cascade_available == 'true'
        continue-on-error: true
        run: |
          echo "Fetching loan data from Cascade..."
          python scripts/ingest_cascade.py
        env:
          CASCADE_USERNAME: ${{ secrets.CASCADEUSERNAME }}
          CASCADE_PASSWORD: ${{ secrets.CASCADEPASSWORD }}

      - name: Ingest HubSpot CRM Data
        id: hubspot
        if: hashFiles('scripts/ingest_hubspot.py') != '' && steps.check-secrets.outputs.hubspot_available == 'true'
        continue-on-error: true
        run: |
          echo "Fetching deals, contacts, and pipeline data from HubSpot..."
          python scripts/ingest_hubspot.py
        env:
          HUBSPOT_TOKEN: ${{ secrets.HUBSPOT_API_TOKEN }}

      - name: Refresh Supabase Views
        id: supabase
        if: hashFiles('scripts/refresh_supabase_views.py') != '' && steps.check-secrets.outputs.supabase_available == 'true'
        run: |
          echo "Refreshing materialized views for agent consumption..."
          python scripts/refresh_supabase_views.py
        env:
          SUPABASE_SERVICE_ROLE: ${{ secrets.SUPABASE_SERVICE_ROLE }}

      - name: Validate Data Quality
        if: hashFiles('scripts/validate_data_quality.py') != ''
        run: |
          echo "Running data quality checks..."
          python scripts/validate_data_quality.py

      - name: Generate Data Manifest
        if: hashFiles('scripts/generate_data_manifest.py') != ''
        run: |
          echo "Creating manifest with data freshness timestamps..."
          python scripts/generate_data_manifest.py

      - name: Signal Agents Data Ready
        if: steps.check-secrets.outputs.slack_available == 'true'
        run: |
          echo "Broadcasting data-ready signal to agent workflows..."
          curl -X POST ${{ secrets.SLACK_BOT_TOKEN }} \
            -H 'Content-Type: application/json' \
            -d '{"text":"âœ… Data pipeline completed at $(date). All agents can now run."}'

      - name: Log to Opik
        if: always() && steps.check-secrets.outputs.opik_available == 'true' && hashFiles('scripts/log_pipeline_metrics.py') != ''
        run: |
          python scripts/log_pipeline_metrics.py \
            --cascade-status ${{ steps.cascade.outcome || 'skipped' }} \
            --hubspot-status ${{ steps.hubspot.outcome || 'skipped' }} \
            --supabase-status ${{ steps.supabase.outcome || 'skipped' }}
        env:
          OPIK_TOKEN: ${{ secrets.OPIK_TOKEN }}

      - name: Alert on Critical Failure
        if: failure() && steps.check-secrets.outputs.slack_available == 'true'
        run: |
          curl -X POST ${{ secrets.SLACK_BOT_TOKEN }} \
            -H 'Content-Type: application/json' \
            -d '{"text":"ðŸš¨ CRITICAL: Data pipeline failed. Agent workflows may operate on stale data."}'

      - name: Upload Pipeline Artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: data-pipeline-logs
          path: |
            logs/
            data/manifest.json
          retention-days: 7
