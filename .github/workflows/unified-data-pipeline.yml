name: Unified Multi-Agent Data Pipeline

on:
  schedule:
    # Run daily at 4:00 AM CET (3:00 AM UTC) - before agent workflows
    - cron: "0 3 * * *"
  workflow_dispatch:

jobs:
  ingest-all-sources:
    runs-on: ubuntu-latest

    steps:
      - name: Check secrets availability
        id: check-secrets
        env:
          SUPABASE_SERVICE_ROLE: ${{ secrets.SUPABASE_SERVICE_ROLE }}
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          SUPABASE_DB_URI_MONITORING: ${{ secrets.SUPABASE_DB_URI_MONITORING }}
          CASCADE_USERNAME: ${{ secrets.CASCADE_USERNAME }}
          CASCADE_PASSWORD: ${{ secrets.CASCADE_PASSWORD }}
          HUBSPOT_TOKEN: ${{ secrets.HUBSPOT_API_KEY || secrets.HUBSPOT_API_TOKEN || secrets.HUBSPOTTOKEN }}
          HUBSPOT_API_KEY: ${{ secrets.HUBSPOT_API_KEY || secrets.HUBSPOT_API_TOKEN || secrets.HUBSPOTTOKEN }}
          OPIK_TOKEN: ${{ secrets.OPIK_TOKEN }}
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
          SLACK_BOT_TOKEN: ${{ secrets.SLACK_BOT_TOKEN }}
        run: |
          if [ -n "$CASCADE_USERNAME" ] && [ -n "$CASCADE_PASSWORD" ]; then
            echo "cascade_available=true" >> $GITHUB_OUTPUT
          else
            echo "cascade_available=false" >> $GITHUB_OUTPUT
          fi
          if [ -n "$HUBSPOT_TOKEN" ]; then
            echo "hubspot_available=true" >> $GITHUB_OUTPUT
          else
            echo "hubspot_available=false" >> $GITHUB_OUTPUT
          fi
          if [ -n "$SUPABASE_SERVICE_ROLE" ] || [ -n "$DATABASE_URL" ] || [ -n "$SUPABASE_DB_URI_MONITORING" ]; then
            echo "supabase_available=true" >> $GITHUB_OUTPUT
          else
            echo "supabase_available=false" >> $GITHUB_OUTPUT
          fi
          if [ -n "$SLACK_WEBHOOK_URL" ] || [ -n "$SLACK_BOT_TOKEN" ]; then
            echo "slack_available=true" >> $GITHUB_OUTPUT
          else
            echo "slack_available=false" >> $GITHUB_OUTPUT
          fi
          if [ -n "$OPIK_TOKEN" ]; then
            echo "opik_available=true" >> $GITHUB_OUTPUT
          else
            echo "opik_available=false" >> $GITHUB_OUTPUT
          fi

      - name: Checkout Repository
        uses: actions/checkout@v4

      - name: Setup Python Environment
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Ingest Cascade Data
        id: cascade
        if: ${{ hashFiles('scripts/fetch_cascade_data.py') != '' && steps.check-secrets.outputs.cascade_available == 'true' }}
        continue-on-error: true
        env:
          CASCADE_USERNAME: ${{ secrets.CASCADE_USERNAME }}
          CASCADE_PASSWORD: ${{ secrets.CASCADE_PASSWORD }}
        run: |
          echo "Fetching loan data from Cascade..."
          python scripts/fetch_cascade_data.py

      - name: Ingest HubSpot CRM Data
        id: hubspot
        if: ${{ hashFiles('scripts/fetch_hubspot_data.py') != '' && steps.check-secrets.outputs.hubspot_available == 'true' }}
        continue-on-error: true
        env:
          HUBSPOT_TOKEN: ${{ secrets.HUBSPOT_API_KEY || secrets.HUBSPOT_API_TOKEN || secrets.HUBSPOTTOKEN }}
          HUBSPOT_API_KEY: ${{ secrets.HUBSPOT_API_KEY || secrets.HUBSPOT_API_TOKEN || secrets.HUBSPOTTOKEN }}
        run: |
          echo "Fetching deals, contacts, and pipeline data from HubSpot..."
          python scripts/fetch_hubspot_data.py

      - name: Refresh Database Tables
        id: database
        if: ${{ hashFiles('scripts/load_csv_to_db.py') != '' && steps.check-secrets.outputs.supabase_available == 'true' }}
        env:
          DATABASE_URL: ${{ secrets.SUPABASE_DB_URI_MONITORING || secrets.DATABASE_URL }}
        run: |
          echo "Refreshing database tables for agent consumption..."
          python scripts/load_csv_to_db.py

      - name: Validate Data Quality
        if: ${{ hashFiles('scripts/check_data_quality_trends.py') != '' }}
        run: |
          echo "Running data quality checks..."
          python scripts/check_data_quality_trends.py

      - name: Generate Data Manifest
        if: ${{ hashFiles('scripts/generate_data_manifest.py') != '' }}
        run: |
          echo "Creating manifest with data freshness timestamps..."
          python scripts/generate_data_manifest.py

      - name: Signal Agents Data Ready
        if: ${{ steps.check-secrets.outputs.slack_available == 'true' }}
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL || secrets.SLACK_BOT_TOKEN }}
        run: |
          echo "Broadcasting data-ready signal to agent workflows..."
          curl -X POST "$SLACK_WEBHOOK_URL" \
            -H 'Content-Type: application/json' \
            -d "{\"text\":\"âœ… Data pipeline completed at $(date). All agents can now run.\"}"

      - name: Log Pipeline Metrics
        if: ${{ always() && hashFiles('scripts/analyze_pipeline_health.py') != '' }}
        env:
          OPIK_TOKEN: ${{ secrets.OPIK_TOKEN }}
          OPIKTOKEN: ${{ secrets.OPIK_TOKEN }}
        run: |
          if [ -f scripts/fetch_opik_metrics.py ]; then
            python scripts/fetch_opik_metrics.py
          fi
          if [ -f scripts/analyze_pipeline_health.py ]; then
            python scripts/analyze_pipeline_health.py
          fi

      - name: Alert on Critical Failure
        if: ${{ failure() && steps.check-secrets.outputs.slack_available == 'true' }}
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL || secrets.SLACK_BOT_TOKEN }}
        run: |
          curl -X POST "$SLACK_WEBHOOK_URL" \
            -H 'Content-Type: application/json' \
            -d '{"text":"ðŸš¨ CRITICAL: Data pipeline failed. Agent workflows may operate on stale data."}'

      - name: Upload Pipeline Artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: data-pipeline-logs
          path: |
            logs/
            data/manifest.json
          retention-days: 7
