name: Model Evaluation Pipeline
permissions:
  contents: read
  pull-requests: write

on:
  push:
    branches: [main, develop]
  pull_request:
    types: [opened, synchronize, reopened]
  schedule:
    - cron: '0 2 * * *'

jobs:
  evaluate-models:
    name: Evaluate ML Models
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v6
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: '3.11'
          cache: 'pip'

      - name: Install dependencies
        run: |
          pip install -r apps/analytics/requirements.txt
          pip install pytest-html pytest-json-report allure-pytest

      - name: Run evaluation tests
        continue-on-error: true
        run: |
          mkdir -p reports
          pytest tests/evaluation/ \
            --html=reports/evaluation-report.html \
            --self-contained-html \
            --json-report \
            --json-report-file=reports/evaluation-metrics.json \
            -v || echo "Evaluation tests completed"

      - name: Generate metrics visualization
        if: always()
        continue-on-error: true
        run: |
          mkdir -p reports/visualizations
          python scripts/evaluation/generate_visualizations.py \
            --metrics-file reports/evaluation-metrics.json \
            --output-dir reports/visualizations/ \
            || echo "Visualization generation skipped"

      - name: Check evaluation thresholds
        if: always()
        continue-on-error: true
        id: threshold-check
        run: |
          mkdir -p config
          touch config/evaluation-thresholds.yml
          python scripts/evaluation/check_thresholds.py \
            --metrics-file reports/evaluation-metrics.json \
            --config config/evaluation-thresholds.yml \
            --output threshold-results.json \
            || echo "Threshold check skipped"

      - name: Upload evaluation reports
        if: always()
        continue-on-error: true
        uses: actions/upload-artifact@v4
        with:
          name: evaluation-reports
          path: |
            reports/
            threshold-results.json
          retention-days: 30
          if-no-files-found: ignore

      - name: Comment on PR with results
        if: github.event_name == 'pull_request' && always()
        continue-on-error: true
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            let body = '## üìä Model Evaluation Results\n\n';

            if (fs.existsSync('reports/evaluation-metrics.json')) {
              const metrics = JSON.parse(fs.readFileSync('reports/evaluation-metrics.json'));
              body += '### Metrics Summary\n' +
                `- **Accuracy**: ${metrics.accuracy || 'N/A'}\n` +
                `- **Precision**: ${metrics.precision || 'N/A'}\n` +
                `- **Recall**: ${metrics.recall || 'N/A'}\n` +
                `- **F1 Score**: ${metrics.f1_score || 'N/A'}\n\n`;
            } else {
              body += '### Metrics Summary\nNo metrics generated in this run.\n\n';
            }

            if (fs.existsSync('threshold-results.json')) {
              const thresholds = JSON.parse(fs.readFileSync('threshold-results.json'));
              body += '### Threshold Status\n' +
                `${thresholds.passed ? '‚úÖ All thresholds passed' : '‚ùå Some thresholds failed'}\n\n`;
            }

            body += `[View detailed report](https://github.com/${{github.repository}}/actions/runs/${{github.run_id}})`;

            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: body
            });

      - name: Send Slack notification on failure
        if: failure() && secrets.SLACK_WEBHOOK_URL != ''
        continue-on-error: true
        uses: slackapi/slack-github-action@v1
        with:
          payload: |
            {
              "text": "üö® Model Evaluation Failed",
              "blocks": [
                {
                  "type": "section",
                  "text": {
                    "type": "mrkdwn",
                    "text": "*Model Evaluation Pipeline Failed* | Repository: ${{ github.repository }} | Branch: ${{ github.ref_name }} | <${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}|View Details>"
                  }
                }
              ]
            }
        env:
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
